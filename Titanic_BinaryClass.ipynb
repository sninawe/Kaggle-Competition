{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the codes in Module 7\n",
    "# load data\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"C:/Users/sanketn/Documents/IU/Kaggle/traintitanic.csv\")\n",
    "test_data = pd.read_csv(\"C:/Users/sanketn/Documents/IU/Kaggle/testtitanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take target out of training set\n",
    "Y = train_data['Survived']\n",
    "train_data = train_data.drop(['Survived'], axis=1)\n",
    "# drop useless feature PassengerID\n",
    "train_data = train_data.drop(['PassengerId'], axis=1)\n",
    "test_data = test_data.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from now on, let's process missing values\n",
    "def countMissing(data):\n",
    "    missing = data.columns[data.isnull().any()].tolist()\n",
    "    return missing\n",
    "misTrain = countMissing(train_data)\n",
    "misTest = countMissing(test_data)\n",
    "misTotal = list(set().union(misTrain, misTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Cabin', 'Embarked'] 3\n"
     ]
    }
   ],
   "source": [
    "print(misTrain, len(misTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Fare', 'Cabin'] 3\n"
     ]
    }
   ],
   "source": [
    "print(misTest, len(misTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cabin', 'Embarked', 'Age', 'Fare'] 4\n"
     ]
    }
   ],
   "source": [
    "print(misTotal, len(misTotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exploreData(data, column):\n",
    "    return data[column].value_counts()\n",
    "def imputation(data, column, value):\n",
    "    data.loc[data[column].isnull(), column] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 891\n",
      "327 418\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[train_data['Cabin'].isnull() == True]), len(train_data))\n",
    "print(len(test_data[test_data['Cabin'].isnull() == True]), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['Cabin'], axis=1)\n",
    "test_data = test_data.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 891\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[train_data['Embarked'].isnull() == True]), len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                                       Name     Sex   Age  SibSp  \\\n",
       "61        1                        Icard, Miss. Amelie  female  38.0      0   \n",
       "829       1  Stone, Mrs. George Nelson (Martha Evelyn)  female  62.0      0   \n",
       "\n",
       "     Parch  Ticket  Fare Embarked  \n",
       "61       0  113572  80.0      NaN  \n",
       "829      0  113572  80.0      NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data['Embarked'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked  Pclass       \n",
       "C         1       count     85.000000\n",
       "                  mean     104.718529\n",
       "                  std       99.093935\n",
       "                  min       26.550000\n",
       "                  25%       49.500000\n",
       "                  50%       78.266700\n",
       "                  75%      110.883300\n",
       "                  max      512.329200\n",
       "          2       count     17.000000\n",
       "                  mean      25.358335\n",
       "                  std       11.345067\n",
       "                  min       12.000000\n",
       "                  25%       13.862500\n",
       "                  50%       24.000000\n",
       "                  75%       37.004200\n",
       "                  max       41.579200\n",
       "          3       count     66.000000\n",
       "                  mean      11.214083\n",
       "                  std        4.871528\n",
       "                  min        4.012500\n",
       "                  25%        7.229200\n",
       "                  50%        7.895800\n",
       "                  75%       14.458300\n",
       "                  max       22.358300\n",
       "Q         1       count      2.000000\n",
       "                  mean      90.000000\n",
       "                  std        0.000000\n",
       "                  min       90.000000\n",
       "                  25%       90.000000\n",
       "                  50%       90.000000\n",
       "                              ...    \n",
       "          3       std        6.721677\n",
       "                  min        6.750000\n",
       "                  25%        7.750000\n",
       "                  50%        7.750000\n",
       "                  75%       10.218725\n",
       "                  max       29.125000\n",
       "S         1       count    127.000000\n",
       "                  mean      70.364862\n",
       "                  std       58.811278\n",
       "                  min        0.000000\n",
       "                  25%       29.250000\n",
       "                  50%       52.000000\n",
       "                  75%       83.475000\n",
       "                  max      263.000000\n",
       "          2       count    164.000000\n",
       "                  mean      20.327439\n",
       "                  std       13.630741\n",
       "                  min        0.000000\n",
       "                  25%       13.000000\n",
       "                  50%       13.500000\n",
       "                  75%       26.000000\n",
       "                  max       73.500000\n",
       "          3       count    353.000000\n",
       "                  mean      14.644083\n",
       "                  std       13.276609\n",
       "                  min        0.000000\n",
       "                  25%        7.854200\n",
       "                  50%        8.050000\n",
       "                  75%       16.100000\n",
       "                  max       69.550000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby(['Embarked', 'Pclass'])['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputation(train_data, 'Embarked', 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 418\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data[test_data['Fare'].isnull() == True]), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3</td>\n",
       "      <td>Storey, Mr. Thomas</td>\n",
       "      <td>male</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass                Name   Sex   Age  SibSp  Parch Ticket  Fare  \\\n",
       "152       3  Storey, Mr. Thomas  male  60.5      0      0   3701   NaN   \n",
       "\n",
       "    Embarked  \n",
       "152        S  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[test_data['Fare'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputation(test_data, 'Fare', 8.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177 891\n",
      "86 418\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[train_data['Age'].isnull() == True]), len(train_data))\n",
    "print(len(test_data[test_data['Age'].isnull() == True]), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass                                               Name     Sex  Age  \\\n",
      "10        3                                   Ilieff, Mr. Ylio    male  NaN   \n",
      "22        1               Flegenheim, Mrs. Alfred (Antoinette)  female  NaN   \n",
      "29        3                                  Samaan, Mr. Elias    male  NaN   \n",
      "33        3  Johnston, Mrs. Andrew G (Elizabeth Lily\" Watson)\"  female  NaN   \n",
      "36        3                                Roth, Miss. Sarah A  female  NaN   \n",
      "39        3                                      Hee, Mr. Ling    male  NaN   \n",
      "41        1                        Franklin, Mr. Thomas Parham    male  NaN   \n",
      "47        3                           Shaughnessy, Mr. Patrick    male  NaN   \n",
      "54        2                  Mangiavacchi, Mr. Serafino Emilio    male  NaN   \n",
      "58        3                          Davison, Mr. Thomas Henry    male  NaN   \n",
      "65        2  Corey, Mrs. Percy C (Mary Phyllis Elizabeth Mi...  female  NaN   \n",
      "76        3                                   Miles, Mr. Frank    male  NaN   \n",
      "83        3                               Demetri, Mr. Marinko    male  NaN   \n",
      "84        2                              Lamb, Mr. John Joseph    male  NaN   \n",
      "85        3                                 Khalil, Mr. Betros    male  NaN   \n",
      "88        3                            O'Donoghue, Ms. Bridget  female  NaN   \n",
      "91        3                                 Pedersen, Mr. Olaf    male  NaN   \n",
      "93        3                                  Guest, Mr. Robert    male  NaN   \n",
      "102       3                                 Foley, Mr. William    male  NaN   \n",
      "107       3                                   Ryan, Mr. Edward    male  NaN   \n",
      "108       3                   Willer, Mr. Aaron (Abi Weller\")\"    male  NaN   \n",
      "111       3                         Shine, Miss. Ellen Natalia  female  NaN   \n",
      "116       3                                   Thomas, Mr. John    male  NaN   \n",
      "121       3                                  Kiernan, Mr. John    male  NaN   \n",
      "124       3                                  Kennedy, Mr. John    male  NaN   \n",
      "127       3                                McCoy, Miss. Alicia  female  NaN   \n",
      "132       3                      Lefebre, Mrs. Frank (Frances)  female  NaN   \n",
      "133       3                              Thomas, Mr. Charles P    male  NaN   \n",
      "146       1                        Hilliard, Mr. Herbert Henry    male  NaN   \n",
      "148       1                          Crafton, Mr. John Bertram    male  NaN   \n",
      "..      ...                                                ...     ...  ...   \n",
      "268       3                        Howard, Miss. May Elizabeth  female  NaN   \n",
      "271       3                                   Fox, Mr. Patrick    male  NaN   \n",
      "273       3                                 Lennon, Miss. Mary  female  NaN   \n",
      "274       3                              Saade, Mr. Jean Nassr    male  NaN   \n",
      "282       3                              Fleming, Miss. Honora  female  NaN   \n",
      "286       3             Franklin, Mr. Charles (Charles Fardon)    male  NaN   \n",
      "288       3                            Mardirosian, Mr. Sarkis    male  NaN   \n",
      "289       3                                   Ford, Mr. Arthur    male  NaN   \n",
      "290       1                Rheims, Mr. George Alexander Lucien    male  NaN   \n",
      "292       3                                  Nasr, Mr. Mustafa    male  NaN   \n",
      "297       3                                  Samaan, Mr. Hanna    male  NaN   \n",
      "301       2                                Malachard, Mr. Noel    male  NaN   \n",
      "304       3                  McCarthy, Miss. Catherine Katie\"\"  female  NaN   \n",
      "312       3                                Sadowitz, Mr. Harry    male  NaN   \n",
      "332       3                                Thomas, Mr. Tannous    male  NaN   \n",
      "339       3                              Betros, Master. Seman    male  NaN   \n",
      "342       3                              Sage, Mr. John George    male  NaN   \n",
      "344       3                van Billiard, Master. James William    male  NaN   \n",
      "357       3                                Lockyer, Mr. Edward    male  NaN   \n",
      "358       3                               O'Keefe, Mr. Patrick    male  NaN   \n",
      "365       3                     Sage, Mrs. John (Annie Bullen)  female  NaN   \n",
      "366       3                                  Caram, Mr. Joseph    male  NaN   \n",
      "380       3                              O'Connor, Mr. Patrick    male  NaN   \n",
      "382       3                         Risien, Mrs. Samuel (Emma)  female  NaN   \n",
      "384       2                     Wheeler, Mr. Edwin Frederick\"\"    male  NaN   \n",
      "408       3                    Riordan, Miss. Johanna Hannah\"\"  female  NaN   \n",
      "410       3                             Naughton, Miss. Hannah  female  NaN   \n",
      "413       3                                 Spector, Mr. Woolf    male  NaN   \n",
      "416       3                                Ware, Mr. Frederick    male  NaN   \n",
      "417       3                           Peter, Master. Michael J    male  NaN   \n",
      "\n",
      "     SibSp  Parch              Ticket     Fare Embarked  \n",
      "10       0      0              349220   7.8958        S  \n",
      "22       0      0            PC 17598  31.6833        S  \n",
      "29       2      0                2662  21.6792        C  \n",
      "33       1      2          W./C. 6607  23.4500        S  \n",
      "36       0      0              342712   8.0500        S  \n",
      "39       0      0                1601  56.4958        S  \n",
      "41       0      0              113778  26.5500        S  \n",
      "47       0      0              370374   7.7500        Q  \n",
      "54       0      0         SC/A.3 2861  15.5792        C  \n",
      "58       1      0              386525  16.1000        S  \n",
      "65       0      0        F.C.C. 13534  21.0000        S  \n",
      "76       0      0              359306   8.0500        S  \n",
      "83       0      0              349238   7.8958        S  \n",
      "84       0      0              240261  10.7083        Q  \n",
      "85       1      0                2660  14.4542        C  \n",
      "88       0      0              364856   7.7500        Q  \n",
      "91       0      0              345498   7.7750        S  \n",
      "93       0      0              376563   8.0500        S  \n",
      "102      0      0              365235   7.7500        Q  \n",
      "107      0      0              383162   7.7500        Q  \n",
      "108      0      0                3410   8.7125        S  \n",
      "111      0      0              330968   7.7792        Q  \n",
      "116      0      0                2681   6.4375        C  \n",
      "121      1      0              367227   7.7500        Q  \n",
      "124      0      0              368783   7.7500        Q  \n",
      "127      2      0              367226  23.2500        Q  \n",
      "132      0      4                4133  25.4667        S  \n",
      "133      1      0                2621   6.4375        C  \n",
      "146      0      0               17463  51.8625        S  \n",
      "148      0      0              113791  26.5500        S  \n",
      "..     ...    ...                 ...      ...      ...  \n",
      "268      0      0         A. 2. 39186   8.0500        S  \n",
      "271      0      0              368573   7.7500        Q  \n",
      "273      1      0              370371  15.5000        Q  \n",
      "274      0      0                2676   7.2250        C  \n",
      "282      0      0              364859   7.7500        Q  \n",
      "286      0      0  SOTON/O.Q. 3101314   7.2500        S  \n",
      "288      0      0                2655   7.2292        C  \n",
      "289      0      0            A/5 1478   8.0500        S  \n",
      "290      0      0            PC 17607  39.6000        S  \n",
      "292      0      0                2652   7.2292        C  \n",
      "297      2      0                2662  21.6792        C  \n",
      "301      0      0              237735  15.0458        C  \n",
      "304      0      0              383123   7.7500        Q  \n",
      "312      0      0             LP 1588   7.5750        S  \n",
      "332      0      0                2684   7.2250        C  \n",
      "339      0      0                2622   7.2292        C  \n",
      "342      1      9            CA. 2343  69.5500        S  \n",
      "344      1      1            A/5. 851  14.5000        S  \n",
      "357      0      0                1222   7.8792        S  \n",
      "358      0      0              368402   7.7500        Q  \n",
      "365      1      9            CA. 2343  69.5500        S  \n",
      "366      1      0                2689  14.4583        C  \n",
      "380      0      0              366713   7.7500        Q  \n",
      "382      0      0              364498  14.5000        S  \n",
      "384      0      0       SC/PARIS 2159  12.8750        S  \n",
      "408      0      0              334915   7.7208        Q  \n",
      "410      0      0              365237   7.7500        Q  \n",
      "413      0      0           A.5. 3236   8.0500        S  \n",
      "416      0      0              359309   8.0500        S  \n",
      "417      1      1                2668  22.3583        C  \n",
      "\n",
      "[86 rows x 9 columns] 418\n"
     ]
    }
   ],
   "source": [
    "print(test_data[test_data['Age'].isnull() == True], len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.00    17\n",
      "21.00    17\n",
      "22.00    16\n",
      "30.00    15\n",
      "18.00    13\n",
      "27.00    12\n",
      "26.00    12\n",
      "25.00    11\n",
      "23.00    11\n",
      "29.00    10\n",
      "36.00     9\n",
      "45.00     9\n",
      "20.00     8\n",
      "17.00     7\n",
      "28.00     7\n",
      "32.00     6\n",
      "31.00     6\n",
      "55.00     6\n",
      "33.00     6\n",
      "39.00     6\n",
      "35.00     5\n",
      "41.00     5\n",
      "47.00     5\n",
      "40.00     5\n",
      "50.00     5\n",
      "42.00     5\n",
      "48.00     5\n",
      "19.00     4\n",
      "43.00     4\n",
      "1.00      3\n",
      "         ..\n",
      "8.00      2\n",
      "63.00     2\n",
      "14.00     2\n",
      "22.50     1\n",
      "62.00     1\n",
      "0.83      1\n",
      "67.00     1\n",
      "28.50     1\n",
      "0.33      1\n",
      "0.17      1\n",
      "38.50     1\n",
      "3.00      1\n",
      "51.00     1\n",
      "5.00      1\n",
      "44.00     1\n",
      "14.50     1\n",
      "59.00     1\n",
      "58.00     1\n",
      "0.75      1\n",
      "0.92      1\n",
      "36.50     1\n",
      "40.50     1\n",
      "11.50     1\n",
      "34.00     1\n",
      "15.00     1\n",
      "7.00      1\n",
      "60.50     1\n",
      "26.50     1\n",
      "76.00     1\n",
      "34.50     1\n",
      "Name: Age, dtype: int64 418\n",
      "24.00    30\n",
      "22.00    27\n",
      "18.00    26\n",
      "19.00    25\n",
      "30.00    25\n",
      "28.00    25\n",
      "21.00    24\n",
      "25.00    23\n",
      "36.00    22\n",
      "29.00    20\n",
      "32.00    18\n",
      "27.00    18\n",
      "35.00    18\n",
      "26.00    18\n",
      "16.00    17\n",
      "31.00    17\n",
      "20.00    15\n",
      "33.00    15\n",
      "23.00    15\n",
      "34.00    15\n",
      "39.00    14\n",
      "17.00    13\n",
      "42.00    13\n",
      "40.00    13\n",
      "45.00    12\n",
      "38.00    11\n",
      "50.00    10\n",
      "2.00     10\n",
      "4.00     10\n",
      "47.00     9\n",
      "         ..\n",
      "71.00     2\n",
      "59.00     2\n",
      "63.00     2\n",
      "0.83      2\n",
      "30.50     2\n",
      "70.00     2\n",
      "57.00     2\n",
      "0.75      2\n",
      "13.00     2\n",
      "10.00     2\n",
      "64.00     2\n",
      "40.50     2\n",
      "32.50     2\n",
      "45.50     2\n",
      "20.50     1\n",
      "24.50     1\n",
      "0.67      1\n",
      "14.50     1\n",
      "0.92      1\n",
      "74.00     1\n",
      "34.50     1\n",
      "80.00     1\n",
      "12.00     1\n",
      "36.50     1\n",
      "53.00     1\n",
      "55.50     1\n",
      "70.50     1\n",
      "66.00     1\n",
      "23.50     1\n",
      "0.42      1\n",
      "Name: Age, dtype: int64 891\n"
     ]
    }
   ],
   "source": [
    "print(exploreData(test_data, 'Age'), len(test_data))\n",
    "print(exploreData(train_data, 'Age'), len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'int64': Index(['Pclass', 'SibSp', 'Parch'], dtype='object'), 'float64': Index(['Age', 'Fare'], dtype='object'), 'object': Index(['Name', 'Sex', 'Ticket', 'Embarked'], dtype='object')}\n"
     ]
    }
   ],
   "source": [
    "# the codes in Module 8\n",
    "# let's start encoding categorical features\n",
    "tmp = train_data.columns.to_series().groupby(train_data.dtypes).groups\n",
    "print({k.name: v for k, v in tmp.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Title from Name\n",
    "titles = [i.split(\",\")[1].split(\".\")[0].strip() for i in train_data[\"Name\"]]\n",
    "train_data[\"Title\"] = pd.Series(titles)\n",
    "train_data = train_data.drop(['Name'], axis=1)\n",
    "titles = [i.split(\",\")[1].split(\".\")[0].strip() for i in test_data[\"Name\"]]\n",
    "test_data[\"Title\"] = pd.Series(titles)\n",
    "test_data = test_data.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr              757\n",
       "Miss            260\n",
       "Mrs             197\n",
       "Master           61\n",
       "Dr                8\n",
       "Rev               8\n",
       "Col               4\n",
       "Major             2\n",
       "Mlle              2\n",
       "Ms                2\n",
       "Don               1\n",
       "Mme               1\n",
       "the Countess      1\n",
       "Dona              1\n",
       "Lady              1\n",
       "Capt              1\n",
       "Sir               1\n",
       "Jonkheer          1\n",
       "Name: Title, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "exploreData(total_data, 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = {\"Mme\": \"Mrs\", \"Mlle\": \"Miss\", \"Ms\": \"Miss\", \"Lady\": \"Miss\", \"Sir\": \"Mr\", \"Dr\": \"Master\"}\n",
    "other = [\"the Countess\",\"Countess\",\"Capt\", \"Col\",\"Don\", \"Major\", \"Rev\", \"Jonkheer\", \"Dona\"]\n",
    "train_data[\"Title\"] = train_data[\"Title\"].replace(new)\n",
    "train_data[\"Title\"] = train_data[\"Title\"].replace(other, \"Other\")\n",
    "test_data[\"Title\"] = test_data[\"Title\"].replace(new)\n",
    "test_data[\"Title\"] = test_data[\"Title\"].replace(other, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat((train_data, pd.get_dummies(train_data[\"Title\"], prefix=\"Title\")), axis=1)\n",
    "del train_data[\"Title\"]\n",
    "test_data = pd.concat((test_data, pd.get_dummies(test_data[\"Title\"], prefix=\"Title\")), axis=1)\n",
    "del test_data[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat((train_data, pd.get_dummies(train_data[\"Sex\"], prefix=\"Sex\")), axis=1)\n",
    "del train_data[\"Sex\"]\n",
    "test_data = pd.concat((test_data, pd.get_dummies(test_data[\"Sex\"], prefix=\"Sex\")), axis=1)\n",
    "del test_data[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               A/5 21171\n",
      "1                PC 17599\n",
      "2        STON/O2. 3101282\n",
      "3                  113803\n",
      "4                  373450\n",
      "5                  330877\n",
      "6                   17463\n",
      "7                  349909\n",
      "8                  347742\n",
      "9                  237736\n",
      "10                PP 9549\n",
      "11                 113783\n",
      "12              A/5. 2151\n",
      "13                 347082\n",
      "14                 350406\n",
      "15                 248706\n",
      "16                 382652\n",
      "17                 244373\n",
      "18                 345763\n",
      "19                   2649\n",
      "20                 239865\n",
      "21                 248698\n",
      "22                 330923\n",
      "23                 113788\n",
      "24                 349909\n",
      "25                 347077\n",
      "26                   2631\n",
      "27                  19950\n",
      "28                 330959\n",
      "29                 349216\n",
      "              ...        \n",
      "388                364858\n",
      "389                349909\n",
      "390                 12749\n",
      "391              PC 17592\n",
      "392             C.A. 2673\n",
      "393            C.A. 30769\n",
      "394                315153\n",
      "395                 13695\n",
      "396                371109\n",
      "397                 13567\n",
      "398                347065\n",
      "399                 21332\n",
      "400                 36928\n",
      "401                 28664\n",
      "402                112378\n",
      "403                113059\n",
      "404                 17765\n",
      "405         SC/PARIS 2166\n",
      "406                 28666\n",
      "407                113503\n",
      "408                334915\n",
      "409    SOTON/O.Q. 3101315\n",
      "410                365237\n",
      "411                 19928\n",
      "412                347086\n",
      "413             A.5. 3236\n",
      "414              PC 17758\n",
      "415    SOTON/O.Q. 3101262\n",
      "416                359309\n",
      "417                  2668\n",
      "Name: Ticket, dtype: object\n"
     ]
    }
   ],
   "source": [
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "print(total_data[\"Ticket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract prefix from Ticket\n",
    "ticket = []\n",
    "for t in list(train_data.Ticket):\n",
    "    if not t.isdigit() :\n",
    "        ticket.append(t.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n",
    "    else:\n",
    "        ticket.append(\"None\")       \n",
    "train_data[\"Ticket\"] = ticket\n",
    "\n",
    "ticket = []\n",
    "for t in list(test_data.Ticket):\n",
    "    if not t.isdigit() :\n",
    "        ticket.append(t.replace(\".\",\"\").replace(\"/\",\"\").strip().split(' ')[0])\n",
    "    else:\n",
    "        ticket.append(\"None\")       \n",
    "test_data[\"Ticket\"] = ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None       957\n",
       "PC          92\n",
       "CA          68\n",
       "A5          28\n",
       "SOTONOQ     24\n",
       "WC          15\n",
       "STONO       14\n",
       "SCPARIS     14\n",
       "A4          10\n",
       "FCC          9\n",
       "SOC          8\n",
       "C            8\n",
       "STONO2       7\n",
       "SOPP         7\n",
       "SCAH         5\n",
       "SCParis      5\n",
       "LINE         4\n",
       "WEP          4\n",
       "PP           4\n",
       "SOTONO2      3\n",
       "FC           3\n",
       "PPP          2\n",
       "SWPP         2\n",
       "SC           2\n",
       "SCA4         2\n",
       "STONOQ       1\n",
       "AQ3          1\n",
       "SCOW         1\n",
       "A            1\n",
       "CASOTON      1\n",
       "AQ4          1\n",
       "SCA3         1\n",
       "LP           1\n",
       "SOP          1\n",
       "AS           1\n",
       "SP           1\n",
       "Fa           1\n",
       "Name: Ticket, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "exploreData(total_data, \"Ticket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other = ['A5', 'STONO2', 'PP', 'SCParis', 'SCA4', 'A4',\n",
    "       'SP', 'SOC', 'WC', 'SOTONOQ', 'WEP', 'STONO', 'C', 'SCPARIS', 'SOP',\n",
    "       'Fa', 'LINE', 'FCC', 'SWPP', 'SCOW', 'PPP', 'SC', 'SCAH', 'AS',\n",
    "       'SOPP', 'FC', 'SOTONO2', 'CASOTON', 'SCA3', 'STONOQ', 'AQ4', 'A',\n",
    "       'LP', 'AQ3']\n",
    "train_data[\"Ticket\"] = train_data[\"Ticket\"].replace(other, \"Other\")\n",
    "test_data[\"Ticket\"] = test_data[\"Ticket\"].replace(other, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat((train_data, pd.get_dummies(train_data[\"Ticket\"], prefix=\"Ticket\")), axis=1)\n",
    "del train_data[\"Ticket\"]\n",
    "test_data = pd.concat((test_data, pd.get_dummies(test_data[\"Ticket\"], prefix=\"Ticket\")), axis=1)\n",
    "del test_data[\"Ticket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    272\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "exploreData(total_data, \"Embarked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat((train_data, pd.get_dummies(train_data[\"Embarked\"], prefix=\"Embarked\")), axis=1)\n",
    "del train_data[\"Embarked\"]\n",
    "test_data = pd.concat((test_data, pd.get_dummies(test_data[\"Embarked\"], prefix=\"Embarked\")), axis=1)\n",
    "del test_data[\"Embarked\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature alignment\n",
    "# for training set\n",
    "col_train = train_data.columns\n",
    "col_test = test_data.columns\n",
    "for index in col_train:\n",
    "    if index in col_test:\n",
    "        pass\n",
    "    else:\n",
    "        del train_data[index]\n",
    "# for testing set\n",
    "col_train = train_data.columns\n",
    "col_test = test_data.columns\n",
    "for index in col_test:\n",
    "    if index in col_train:\n",
    "        pass\n",
    "    else:\n",
    "        del test_data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min-max scaling\n",
    "train_age = train_data[\"Age\"]\n",
    "test_age = test_data[\"Age\"]\n",
    "train_data = (train_data - train_data.min()) / (train_data.max() - train_data.min())\n",
    "test_data = (test_data - test_data.min()) / (test_data.max() - test_data.min())\n",
    "train_data[\"Age\"] = train_age\n",
    "test_data[\"Age\"] = test_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# impute age\n",
    "# decompose the whole dataset\n",
    "total_data = train_data\n",
    "total_data = total_data.append(test_data)\n",
    "test_age = total_data[total_data[\"Age\"].isnull() == True]\n",
    "train_age = total_data[total_data[\"Age\"].isnull() == False]\n",
    "age = train_age[\"Age\"]\n",
    "train_age = train_age.drop(['Age'], axis=1)\n",
    "test_age = test_age.drop(['Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfe = RandomForestRegressor(n_estimators = 500)\n",
    "rfe.fit(train_age, age)\n",
    "res = rfe.predict(test_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputation(total_data, \"Age\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = total_data[0:len(train_data)]\n",
    "test_data = total_data[len(train_data): len(total_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanketn\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\sanketn\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train_data[\"Age\"] = (train_data[\"Age\"] - train_data[\"Age\"].min()) / (train_data[\"Age\"].max() - train_data[\"Age\"].min())\n",
    "test_data[\"Age\"] = (test_data[\"Age\"] - test_data[\"Age\"].min()) / (test_data[\"Age\"].max() - test_data[\"Age\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the codes in Module 9\n",
    "# train regularized logistic regression model of l1 norm\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(penalty = \"l1\")\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train regularized logistic regression model of l2 norm\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(penalty = \"l2\")\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanketn\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    parameter     score\n",
      "7       3.000  0.833904\n",
      "9      30.000  0.829422\n",
      "8      10.000  0.829422\n",
      "10    100.000  0.828311\n",
      "11    300.000  0.828311\n",
      "12   1000.000  0.828311\n",
      "13   3000.000  0.828311\n",
      "6       1.000  0.819310\n",
      "5       0.300  0.806936\n",
      "3       0.030  0.786698\n",
      "4       0.100  0.785587\n",
      "0       0.001  0.616170\n",
      "1       0.003  0.616170\n",
      "2       0.010  0.616170\n"
     ]
    }
   ],
   "source": [
    "# cross validation on L1 regularized logistic regression\n",
    "from sklearn import cross_validation\n",
    "alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    lm = linear_model.LogisticRegression(penalty = \"l1\", C = a)\n",
    "    scores.append(cross_validation.cross_val_score(lm, train_data, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "scores = pd.DataFrame({'parameter': alphas, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    parameter     score\n",
      "10    100.000  0.828311\n",
      "11    300.000  0.828311\n",
      "12   1000.000  0.828311\n",
      "13   3000.000  0.828311\n",
      "7       3.000  0.828298\n",
      "8      10.000  0.827200\n",
      "9      30.000  0.827200\n",
      "6       1.000  0.822680\n",
      "1       0.003  0.810332\n",
      "5       0.300  0.809197\n",
      "4       0.100  0.795725\n",
      "2       0.010  0.786698\n",
      "3       0.030  0.785587\n",
      "0       0.001  0.679094\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "scores = []\n",
    "for a in alphas:\n",
    "    lm = linear_model.LogisticRegression(penalty = \"l2\", C = a)\n",
    "    scores.append(cross_validation.cross_val_score(lm, train_data, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "scores = pd.DataFrame({'parameter': alphas, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train regularized logistic regression model of l1 norm\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(penalty = \"l1\", C = 3)\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train regularized logistic regression model of l2 norm\n",
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(penalty = \"l2\", C = 300)\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LogisticRegression(C = 1e6)\n",
    "lm.fit(train_data, Y)\n",
    "res = lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835016835016835"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(lm.predict(train_data), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0893604072429595\n",
      "4.25798417332627\n",
      "5.103561373352274\n",
      "4.215184581748553\n",
      "5.1890643256931455\n",
      "5.124832747314951\n",
      "4.4635596294863475\n",
      "5.170489110973666\n",
      "5.223141687148111\n",
      "4.298190040080551\n",
      "5.04648904809204\n",
      "4.526208155520975\n",
      "5.060783411840379\n",
      "5.948822265437269\n",
      "5.029355040562278\n",
      "4.72136651290664\n",
      "5.281403687849563\n",
      "4.409819716632066\n",
      "5.164520811753083\n",
      "5.242752009734153\n",
      "4.441392863808032\n",
      "4.428698585140183\n",
      "5.033812196642259\n",
      "4.124911707352609\n",
      "5.1791674948059505\n",
      "5.936823181802359\n",
      "5.116006698053338\n",
      "4.569766852074592\n",
      "5.069942685503028\n",
      "5.1158776756446915\n",
      "4.250295720099748\n",
      "4.354450519425506\n",
      "5.105920022672734\n",
      "4.9295219449269725\n",
      "4.1614593112599545\n",
      "4.298925717573923\n",
      "5.087707961242443\n",
      "5.067124821860476\n",
      "5.112535503352124\n",
      "5.045226486246729\n",
      "5.2633351364315715\n",
      "4.378863470621566\n",
      "5.157041303532468\n",
      "4.384373670923934\n",
      "5.054747443750738\n",
      "5.12845112787226\n",
      "5.216917753464594\n",
      "5.105920022672734\n",
      "5.137437520751712\n",
      "5.065633225208966\n",
      "5.290615238347511\n",
      "5.067109725541725\n",
      "4.410709852786411\n",
      "4.397178701925161\n",
      "4.700961988664803\n",
      "4.233111059725234\n",
      "4.317297967588292\n",
      "5.124703974507672\n",
      "4.38298214238112\n",
      "5.527791342213451\n",
      "5.073734259856596\n",
      "4.247383118260334\n",
      "4.355985909917972\n",
      "5.256725450988236\n",
      "4.156764483582928\n",
      "5.0474953175200215\n",
      "4.3793983095380895\n",
      "5.054764496652408\n",
      "5.404757528835255\n",
      "5.166107979664736\n",
      "4.407896757755898\n",
      "5.548445137796836\n",
      "4.337459410827146\n",
      "5.119743054240406\n",
      "5.169636742600349\n",
      "5.095624609137827\n",
      "5.1158776756446915\n",
      "5.164038125022904\n",
      "4.364341693594379\n",
      "5.138754856904131\n",
      "5.073843748331792\n",
      "5.129322113607482\n",
      "5.075520563531692\n",
      "4.128562101996174\n",
      "4.293827171139405\n",
      "5.3091899315803825\n",
      "5.308455770492801\n",
      "5.12845112787226\n",
      "4.595764106698815\n",
      "5.088043895552272\n",
      "5.129225163810275\n",
      "5.0607715479726005\n",
      "4.357933260116884\n",
      "5.2316710113575065\n",
      "5.5420649592052875\n",
      "5.164038125022904\n",
      "4.7911779466015085\n",
      "4.123579524993332\n",
      "4.457847889668903\n",
      "4.446255151981093\n",
      "5.1203479279257476\n",
      "5.1158776756446915\n",
      "4.117412992572188\n",
      "5.167893160359442\n",
      "5.2740295634753265\n",
      "5.1203479279257476\n",
      "5.067100896338266\n",
      "5.12096018097191\n",
      "5.223237937116371\n",
      "5.0673512519262545\n",
      "4.352904640304473\n",
      "5.047724784916048\n",
      "5.0737820391524915\n",
      "5.07652928954092\n",
      "5.044203550230318\n",
      "5.06711721417303\n",
      "5.775726173407249\n",
      "4.396283399740518\n",
      "4.348987865018789\n",
      "5.365231761360334\n",
      "4.399959410827146\n",
      "5.12845112787226\n",
      "4.431572820411139\n",
      "4.413146656034621\n",
      "4.5038474027809485\n",
      "5.037280775285292\n",
      "5.263779022819823\n",
      "5.087991325613443\n",
      "5.047635995466745\n",
      "5.313999308560638\n",
      "5.167845341622094\n",
      "5.06072588391277\n",
      "5.359028960206799\n",
      "4.397178701925161\n",
      "4.346045505934014\n",
      "4.331370626248115\n",
      "4.168253888486804\n",
      "4.237657427218181\n",
      "5.038652593054626\n",
      "4.111694493321032\n",
      "5.25789286310741\n",
      "5.0737639807169375\n",
      "5.104379117821468\n",
      "5.054684508606954\n",
      "4.29930497486742\n",
      "4.353059070856899\n",
      "5.111789888821907\n",
      "5.189737218690594\n",
      "4.569240181294395\n",
      "4.523642883369369\n",
      "4.654568283777062\n",
      "4.106058735911192\n",
      "5.47929594569413\n",
      "5.365569532218791\n",
      "5.134162088501653\n",
      "4.446101448384322\n",
      "5.03855680094029\n",
      "5.138408839277627\n",
      "5.0887084355692656\n",
      "6.147349101348809\n",
      "5.328658490168623\n",
      "4.498313177218754\n",
      "5.103552401281446\n",
      "5.043693024036605\n",
      "5.28383169814673\n",
      "5.124340382751759\n",
      "4.2985919542367235\n",
      "5.776848987739982\n",
      "4.243789197957889\n",
      "5.132270426187105\n",
      "4.5837718454530485\n",
      "5.283033253372656\n",
      "5.043928122246252\n",
      "5.06711721417303\n",
      "4.491375582260866\n",
      "5.092438927525935\n",
      "5.1729984559525555\n",
      "4.391295816816033\n",
      "4.388805810551602\n",
      "5.19989596045234\n",
      "6.181004118555653\n",
      "4.346326689206785\n",
      "5.376488725229407\n",
      "4.346125597083646\n",
      "5.114983001949028\n",
      "4.43414480424359\n",
      "5.180204761197027\n",
      "4.316499494677078\n",
      "5.291686190961138\n",
      "5.200133477102908\n",
      "4.4081205833020585\n",
      "4.305154780366175\n",
      "5.07037094522442\n",
      "4.29702926999472\n",
      "4.302820785565017\n",
      "4.605312646078939\n",
      "5.263779022819823\n",
      "5.301045893663143\n",
      "5.105920022672734\n",
      "4.3384408668262475\n",
      "5.120454245412047\n",
      "6.1790207364099\n",
      "5.178215485482269\n",
      "5.321091653338345\n",
      "5.049048013615936\n",
      "5.02858900362482\n",
      "5.174058834297279\n",
      "5.104666841176675\n",
      "5.038557786043608\n",
      "4.251029324032643\n",
      "5.087986367624663\n",
      "4.440497561623388\n",
      "5.0737354072429595\n",
      "4.388805810551602\n",
      "5.22455996704809\n",
      "4.212170796544084\n",
      "5.111797627003876\n",
      "4.541401369426391\n",
      "4.179651356901829\n",
      "4.388581985005442\n",
      "5.038575844479162\n",
      "4.362202205965298\n",
      "5.404217503904894\n",
      "5.1158776756446915\n",
      "4.2694847723620075\n",
      "5.073868216750009\n",
      "4.304930954820014\n",
      "5.063868009031906\n",
      "4.299444984889912\n",
      "5.175745276160273\n",
      "4.230989391693145\n",
      "5.129208584051999\n",
      "4.792559042192823\n",
      "5.368176677832547\n",
      "4.338217041280087\n",
      "5.073920525131367\n",
      "4.568093597486749\n",
      "4.372808873501929\n",
      "4.304930954820014\n",
      "4.418181868444865\n",
      "5.051431044746734\n",
      "5.062005292150627\n",
      "4.3793983095380895\n",
      "5.073728561514819\n",
      "5.138360828697975\n",
      "4.393252526928407\n",
      "5.095631954901762\n",
      "4.449709132044237\n",
      "4.265215509031658\n",
      "4.721512770184123\n",
      "5.2133783257601385\n",
      "5.172798092458626\n",
      "4.601471344564282\n",
      "5.1547744922966094\n",
      "5.372693250055276\n",
      "5.240974918419594\n",
      "4.3835865355070345\n",
      "4.166667805027519\n",
      "5.188817441353484\n",
      "4.668508191619946\n",
      "5.263779022819823\n",
      "5.365915497765619\n",
      "4.4876746486814465\n",
      "4.247368109566933\n",
      "5.105920022672734\n",
      "4.450315990519815\n",
      "5.322107539503095\n",
      "5.111256954901762\n",
      "4.6410239215732725\n",
      "4.258903952029341\n",
      "4.329747786357663\n",
      "5.095401650320377\n",
      "4.5392521179338345\n",
      "4.242428648022386\n",
      "5.105920022672734\n",
      "4.6571701501334895\n",
      "5.314042785482418\n",
      "4.43994413252863\n",
      "5.287846156196674\n",
      "5.233782473821007\n",
      "5.658778003507232\n",
      "5.120345431747061\n",
      "5.038672794276369\n",
      "5.054757809092199\n",
      "4.35656604292344\n",
      "5.1678937079362015\n",
      "5.138505789074834\n",
      "5.0737726714633995\n",
      "4.523642883369369\n",
      "5.0737639807169375\n",
      "4.127008830388911\n",
      "4.101739789649335\n",
      "4.450527493755324\n",
      "5.088095404001363\n",
      "5.08803452786318\n",
      "4.156764483582928\n",
      "5.084312224429462\n",
      "4.21463143210462\n",
      "4.271407180402788\n",
      "4.649345845193799\n",
      "5.105920022672734\n",
      "5.186179874290798\n",
      "5.054510924752538\n",
      "4.374131064697955\n",
      "5.12845112787226\n",
      "4.214276717376803\n",
      "4.189774243136557\n",
      "4.104213318183164\n",
      "4.405981397739474\n",
      "4.150509253332604\n",
      "4.114142908051045\n",
      "4.48468107419073\n",
      "4.399300296932386\n",
      "5.1203479279257476\n",
      "4.582316163457512\n",
      "5.103557117171943\n",
      "4.3559974336671585\n",
      "4.704059067849534\n",
      "4.36232673788465\n",
      "4.359691059028702\n",
      "5.0737354072429595\n",
      "5.11179586700223\n",
      "4.3887430346292735\n",
      "4.370141971472671\n",
      "6.1790207364099\n",
      "4.269982471128197\n",
      "5.579644526788353\n",
      "4.450539816065977\n",
      "5.192669189869478\n",
      "4.078913702816732\n",
      "5.113135600522403\n",
      "4.32398728681015\n",
      "4.340501721616866\n",
      "5.102063334215349\n",
      "4.335767116721933\n",
      "5.1158776756446915\n",
      "4.1615018605689755\n",
      "4.328945836709366\n",
      "5.314060843917972\n",
      "4.318615255655743\n",
      "4.2963723908691325\n",
      "4.603052938534664\n",
      "4.370754266888816\n",
      "4.346045505934014\n",
      "4.450539816065977\n",
      "4.3384408668262475\n",
      "4.49801196518057\n",
      "5.092323953084115\n",
      "5.045417002201022\n",
      "5.273284910720409\n",
      "5.080832395442622\n",
      "4.329517341928612\n",
      "5.077168469300533\n",
      "5.112233746253068\n",
      "5.116006698053338\n",
      "5.120454245412047\n",
      "4.112837567095055\n",
      "4.473644276079439\n",
      "5.069942685503028\n",
      "5.069942685503028\n",
      "5.710403137728603\n",
      "4.397530890003429\n",
      "5.342387694896434\n",
      "5.189006797765536\n",
      "5.216917753464594\n",
      "5.138362207368095\n",
      "4.597720811365676\n",
      "5.132971145048741\n",
      "5.105920022672734\n",
      "4.106093520951871\n",
      "4.122737134695921\n",
      "5.064586885231998\n",
      "5.054757809092199\n",
      "4.143621665488687\n",
      "5.171145990099253\n",
      "4.226997482215399\n",
      "5.0737354072429595\n",
      "4.393090232309566\n",
      "5.060597865820139\n",
      "5.054741229333923\n",
      "4.4702231482486825\n",
      "5.112108301737223\n",
      "5.157716004340636\n",
      "4.214744131171674\n",
      "5.1158776756446915\n",
      "4.319382602582605\n",
      "5.510169296440472\n",
      "4.450539816065977\n",
      "5.13305211207949\n",
      "4.293955751772306\n",
      "4.381493141601149\n",
      "5.067109475991061\n",
      "5.182849687927392\n",
      "4.145017538243612\n",
      "5.199970636478084\n",
      "5.073766693283075\n",
      "5.147896458149117\n",
      "4.580625973850886\n",
      "4.330928209444238\n",
      "4.370720064440464\n",
      "5.235265638032623\n",
      "5.103568981039722\n",
      "5.082870699561018\n",
      "5.136692517884036\n",
      "5.060822410465394\n",
      "4.445359849796451\n",
      "5.40419944546934\n",
      "4.29579322913289\n",
      "5.067108242102201\n",
      "5.175745276160273\n",
      "5.1158776756446915\n",
      "5.089647719837495\n",
      "4.21409217686773\n",
      "4.43994413252863\n",
      "5.300132451684416\n",
      "5.179647845341502\n",
      "4.475481604889555\n",
      "4.410556096001024\n",
      "4.388805810551602\n",
      "5.127824897423251\n",
      "5.157041303532468\n",
      "5.067105778321605\n",
      "5.129214546383569\n",
      "5.164303188461499\n",
      "5.093760380972844\n",
      "5.1341586209915295\n",
      "4.388310833729726\n",
      "4.307086347207086\n",
      "5.263779022819823\n",
      "5.157723612028082\n",
      "4.122795946373946\n",
      "5.092323953084115\n",
      "4.54119945021028\n",
      "5.043600547773918\n",
      "4.415684881683766\n",
      "4.210717201239206\n",
      "5.2449908589852265\n",
      "4.651636392805328\n",
      "5.361901508274058\n",
      "4.398081467744711\n",
      "4.609841925277815\n",
      "5.060880361637587\n",
      "5.111256954901762\n",
      "4.370754266888816\n",
      "5.113968686540467\n",
      "4.138663480538266\n",
      "4.304215713882179\n",
      "4.180740264625314\n",
      "5.095003013016832\n",
      "4.423646118237164\n",
      "4.579565853004139\n",
      "5.10693835043157\n",
      "4.141095736378654\n",
      "4.418528272746714\n",
      "5.12845112787226\n",
      "5.129215796121183\n",
      "4.6612347127018925\n",
      "4.329060246515397\n",
      "4.638575021455096\n",
      "5.263779022819823\n",
      "4.360156691946912\n",
      "5.178301613866207\n",
      "4.348250021393462\n",
      "4.608115012461782\n",
      "5.12845112787226\n",
      "5.223189776877854\n",
      "4.43994413252863\n",
      "4.490471404630825\n",
      "5.133051864794588\n",
      "5.091707958893466\n",
      "5.2133783257601385\n",
      "5.223286303430478\n",
      "4.547277717523324\n",
      "4.331232844542278\n",
      "5.073903853229586\n",
      "4.341285512692962\n",
      "4.445359849796451\n",
      "5.14479241033372\n",
      "5.073750646172453\n",
      "5.028747181614516\n",
      "5.521740474883518\n",
      "4.43994413252863\n",
      "5.388401875727281\n",
      "5.618741321998489\n",
      "4.142630515217174\n",
      "5.175745276160273\n",
      "4.23530179324969\n",
      "4.526883203843704\n",
      "5.138408839277627\n",
      "5.055990229664809\n",
      "5.10693835043157\n",
      "5.067078189950944\n",
      "4.473935268217259\n",
      "4.795939248349315\n",
      "5.067124821860476\n",
      "5.097408562442665\n",
      "4.492274928153709\n",
      "5.214046823389863\n",
      "4.3096388917881905\n",
      "5.088028549682856\n",
      "5.043693024036605\n",
      "5.067106763424922\n",
      "5.1067685797082785\n",
      "5.211640483915467\n",
      "4.066834810229055\n",
      "4.10960730638751\n",
      "4.531294358537184\n",
      "4.350392256774353\n",
      "5.122043409170911\n",
      "5.115482111611987\n",
      "5.129207105374721\n",
      "5.12845112787226\n",
      "4.2025286542685105\n",
      "4.482379681415564\n",
      "5.088011072317469\n",
      "4.347012465499904\n",
      "4.428474759594023\n",
      "5.166338058458873\n",
      "4.468096382906888\n",
      "5.15771424433899\n",
      "4.171468148655817\n",
      "5.0737726714633995\n",
      "5.116006698053338\n",
      "4.340477917709432\n",
      "5.087707961242443\n",
      "5.253886237291271\n",
      "4.638575021455096\n",
      "4.6275654276313665\n",
      "5.235265638032623\n",
      "4.421289802745685\n",
      "4.2963723908691325\n",
      "5.087707961242443\n",
      "5.087009023893473\n",
      "5.237606210878546\n",
      "5.138447837902642\n",
      "4.370572958016755\n",
      "4.316499494677078\n",
      "4.1813127795653795\n",
      "5.104192957481618\n",
      "4.193981219872543\n",
      "4.3302122558731755\n",
      "5.37646186794971\n",
      "5.382512735279644\n",
      "4.425677150142969\n",
      "4.446930816015033\n",
      "4.6408876700732185\n",
      "4.322711347207086\n",
      "4.335247650973704\n",
      "5.212615577163768\n",
      "4.307620720573452\n",
      "4.201360105196615\n",
      "4.364133772806208\n",
      "5.146017719969189\n",
      "5.07373402857284\n",
      "5.073765459394215\n",
      "4.601471344564282\n",
      "4.37907052737525\n",
      "4.375546545220094\n",
      "4.302598955047092\n",
      "5.216674414449882\n",
      "5.263779022819823\n",
      "5.247605626217502\n",
      "4.370804746692843\n",
      "5.12845112787226\n",
      "5.067281516046247\n",
      "5.1525189702695595\n",
      "5.054748441403107\n",
      "5.575114866474139\n",
      "5.087707961242443\n",
      "5.157711748160304\n",
      "4.84920583953299\n",
      "4.509145670124137\n",
      "4.202548722371735\n",
      "5.105920022672734\n",
      "5.038575844479162\n",
      "5.055311934473054\n",
      "4.428698585140183\n",
      "4.262556251676555\n",
      "5.071880027335402\n",
      "5.157716004340636\n",
      "4.392233244975511\n",
      "4.3252709921717605\n",
      "4.705887770184123\n",
      "4.2060297923943475\n",
      "5.144127790461255\n",
      "4.184082056276292\n",
      "4.593460154705622\n",
      "4.627822860286226\n",
      "5.0737820391524915\n",
      "5.12845112787226\n",
      "5.189010848055473\n",
      "4.459064635438896\n",
      "5.3428032029164125\n",
      "5.2110192551923475\n",
      "4.47949070927766\n",
      "5.245520697287066\n",
      "4.321280475328428\n",
      "5.372655170481924\n",
      "5.116006698053338\n",
      "4.400627468876562\n",
      "4.430852130661047\n",
      "5.1158776756446915\n",
      "4.312181029921577\n",
      "5.300140059371862\n",
      "4.191502976452251\n",
      "5.21644217877788\n",
      "5.138399471588535\n",
      "4.1151024135740615\n",
      "4.45685775597437\n",
      "4.33709163294022\n",
      "5.948822265437269\n",
      "5.112924606013024\n",
      "5.062005292150627\n",
      "5.263779022819823\n",
      "5.1890643256931455\n",
      "4.480629512664644\n",
      "5.222247506712867\n",
      "5.119934634058704\n",
      "4.348096234460409\n",
      "4.3537421267675365\n",
      "5.127979307892007\n",
      "4.299146472186501\n",
      "5.104883377121471\n",
      "5.067112957992698\n",
      "5.06786547487946\n",
      "4.583476144714681\n",
      "4.756077421032481\n",
      "4.090031962748171\n",
      "5.10355961335063\n",
      "5.133052353606303\n",
      "5.003428816877356\n",
      "5.40416020166064\n",
      "4.161020790910822\n",
      "4.2810751526557285\n",
      "5.266325992054519\n",
      "4.370754266888816\n",
      "5.157716004340636\n",
      "4.443689403376739\n",
      "5.960470911055634\n",
      "5.117063486090051\n",
      "5.0607715479726005\n",
      "4.106093520951871\n",
      "5.255095885465144\n",
      "5.144758475984148\n",
      "5.091707958893466\n",
      "4.395525839152632\n",
      "5.054748441403107\n",
      "4.492587165609489\n",
      "5.094248748796476\n",
      "5.080725347303486\n",
      "5.1158776756446915\n",
      "4.328594289418632\n",
      "5.0671488923412165\n",
      "5.0690221989442\n",
      "5.048974713130692\n",
      "4.420878484518941\n",
      "5.1158776756446915\n",
      "5.201794809082626\n",
      "4.331152034990399\n",
      "4.6835180904001685\n",
      "4.518706805672929\n",
      "5.2475669833269425\n",
      "4.345097301065945\n",
      "5.200110021557197\n",
      "5.076400804152932\n",
      "4.490558200994752\n",
      "4.346045505934014\n",
      "5.12096018097191\n",
      "5.28653508209767\n",
      "4.265779756608235\n",
      "4.546565587867443\n",
      "4.1735881274954245\n",
      "5.014890966671629\n",
      "4.398305293290871\n",
      "4.43994413252863\n",
      "5.04903143385766\n",
      "5.091806739197166\n",
      "5.0491701425827715\n",
      "6.310293264304232\n",
      "5.227673738230117\n",
      "5.052149726878419\n",
      "4.1339880326561484\n",
      "5.060860743566578\n",
      "5.53923619774773\n",
      "4.859720078700536\n",
      "4.478724251481917\n",
      "5.312898599453989\n",
      "5.054905029812348\n",
      "5.049032667746521\n",
      "4.231503359816993\n",
      "4.17566446660449\n",
      "5.030487327177725\n",
      "5.144758475984148\n",
      "5.095600524080386\n",
      "4.563208135498794\n",
      "4.670796390432429\n",
      "5.300140059371862\n",
      "5.049614014741922\n",
      "4.4628998012732755\n",
      "5.273221986573183\n",
      "4.261650249769225\n",
      "4.191450135169656\n",
      "5.077374864594399\n",
      "5.095629986356617\n",
      "5.119182117171943\n",
      "4.487601783834956\n",
      "4.564508294995976\n",
      "4.275631721571904\n",
      "4.161036285169533\n",
      "5.0474953175200215\n",
      "4.097133549341815\n",
      "4.350392256774353\n",
      "4.383397846666335\n",
      "5.129320905821556\n",
      "4.6707459106284\n",
      "5.054733883569988\n",
      "4.420224540958752\n",
      "4.361978380419137\n",
      "5.1678001644142775\n",
      "5.16783812955291\n",
      "4.28684319697004\n",
      "5.059221723167337\n",
      "4.428698585140183\n",
      "4.638798847001256\n",
      "4.1379254907467296\n",
      "5.060822410465394\n",
      "4.53046707520787\n",
      "5.049614262292443\n",
      "4.363602072774924\n",
      "5.1112659269725915\n",
      "4.299137275030839\n",
      "5.019019909032731\n",
      "4.43994413252863\n",
      "4.331152034990399\n",
      "4.331152034990399\n",
      "5.12549240682255\n",
      "5.627597967201444\n",
      "5.188817441353484\n",
      "5.1158776756446915\n",
      "5.1158776756446915\n",
      "4.433505461800502\n",
      "4.239207694141191\n",
      "4.5027578824352705\n",
      "5.104409548571255\n",
      "5.147900714329449\n",
      "4.827078898691656\n",
      "5.0832939926070235\n",
      "4.388805810551602\n",
      "4.0808780651476075\n",
      "5.147890263581342\n",
      "4.297441916302256\n",
      "5.033287230514604\n",
      "5.167951659108393\n",
      "5.080745696027331\n",
      "4.750303658300178\n",
      "4.294213656475541\n",
      "5.1203419497454234\n",
      "4.29930497486742\n",
      "5.178301613866207\n",
      "4.196113675061079\n",
      "5.104192957481618\n",
      "5.260219071727363\n",
      "5.060735632544484\n",
      "4.381493141601149\n",
      "5.038559264720886\n",
      "4.442749644792588\n",
      "4.254155541137507\n",
      "5.143101046302718\n",
      "5.186346088012273\n",
      "5.157743152117319\n",
      "5.088140845349479\n",
      "5.357706177320027\n",
      "4.7559163714086505\n",
      "5.116006698053338\n",
      "4.970952730094155\n",
      "5.049029955180382\n",
      "5.263779022819823\n",
      "5.003905151795488\n",
      "5.133052601156824\n",
      "4.484224971096012\n",
      "5.025188366017485\n",
      "4.071410169999185\n",
      "4.13240709634797\n",
      "5.268556456536004\n",
      "5.095591006732429\n",
      "5.095601902750506\n",
      "5.049015190381134\n",
      "5.290082071681848\n",
      "5.128402033440583\n",
      "4.35194803350476\n",
      "5.263779022819823\n",
      "4.290904382594048\n",
      "6.181004118555653\n",
      "4.414876175649711\n",
      "5.095639166970946\n",
      "4.485670216994046\n",
      "4.375216585886704\n",
      "5.147948695188459\n",
      "5.138361059981731\n",
      "5.183786691772692\n",
      "4.428698585140183\n",
      "4.443689403376739\n",
      "4.199272345704926\n",
      "5.028054118240847\n",
      "5.111743699333988\n",
      "5.14789174225862\n",
      "4.235026361380409\n",
      "5.04903143385766\n",
      "4.485670216994046\n",
      "4.1939749653665945\n",
      "5.103559114261988\n",
      "5.237248320437358\n",
      "4.43923747142096\n",
      "5.369754121494188\n",
      "5.143119104738272\n",
      "4.2810751526557285\n",
      "5.080747456028976\n",
      "4.446281011057091\n",
      "5.2864466948181645\n",
      "5.269193522083527\n",
      "4.496811026510393\n",
      "5.1118442333163365\n",
      "4.223000420465802\n",
      "5.139929030095605\n",
      "5.2841727700004\n",
      "5.1002055558524075\n",
      "5.144758475984148\n",
      "4.366381025496326\n",
      "5.263779022819823\n",
      "4.623168507260047\n",
      "5.049987544019335\n",
      "4.2947687029717\n",
      "5.087707961242443\n",
      "5.080743199848644\n",
      "5.049063586159254\n",
      "4.304775035996621\n",
      "5.067163820485492\n",
      "5.164038125022904\n",
      "5.169636742600349\n",
      "4.388165445889911\n",
      "5.060775804152932\n",
      "4.288748990206977\n",
      "4.141823169403676\n",
      "5.183554492856771\n",
      "5.043693024036605\n",
      "5.273216195682457\n",
      "6.1790207364099\n",
      "5.1890549580040535\n",
      "4.4020370574745575\n",
      "4.245679181441085\n",
      "5.366861326883427\n",
      "5.855123179280871\n",
      "5.05591260284183\n",
      "4.072020913659204\n",
      "4.568093597486749\n",
      "5.076911968991231\n",
      "4.460770926452393\n",
      "4.406656154664001\n",
      "5.339209996622344\n",
      "5.087707961242443\n",
      "5.323283982657015\n",
      "4.33300678311196\n",
      "4.3600325722529245\n",
      "6.181004118555653\n",
      "4.3384408668262475\n",
      "4.523642883369369\n",
      "4.3779150312193895\n",
      "4.157375755230394\n",
      "5.114994118058598\n",
      "5.045898759623016\n",
      "5.10355961335063\n",
      "4.396528172694829\n",
      "4.1677030698847854\n",
      "5.342911544005245\n",
      "4.3879298540766865\n",
      "5.033765460239\n",
      "5.060905848329229\n",
      "5.054748441403107\n",
      "5.1158776756446915\n",
      "4.54190954414827\n",
      "4.375754850552703\n",
      "5.167845341622094\n",
      "5.073956522038464\n",
      "4.370530441342655\n",
      "5.095591006732429\n",
      "5.932702525259832\n",
      "4.362202205965298\n",
      "4.057939741629895\n",
      "5.134118292916613\n",
      "4.106750913577416\n",
      "5.157705553592528\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = train_data.as_matrix()\n",
    "for i in a:\n",
    "    print(sum(np.square(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "# RBF function\n",
    "def rbf(data, centers, sigma):\n",
    "    res = np.ndarray(shape = (len(data), len(centers)))\n",
    "    i = 0\n",
    "    for row in data:\n",
    "        tmp = []\n",
    "        for center in centers:\n",
    "            tmp.append(math.exp(-1.0 * sum(np.square(row - center)) / (2 * sigma * sigma)))\n",
    "        res[i, :] = tmp\n",
    "        i = i + 1\n",
    "    return res\n",
    "# select k centers from data\n",
    "def selectCenters(data, k):\n",
    "    tmp = np.random.choice(len(data), k)\n",
    "    return data[tmp,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centers = selectCenters(train_data.as_matrix(), train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 19\n"
     ]
    }
   ],
   "source": [
    "rbfX = rbf(train_data.as_matrix(), centers, 1.0)\n",
    "print(len(rbfX),len(centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbfTest = rbf(test_data.as_matrix(), centers, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(penalty = \"l1\")\n",
    "lm.fit(rbfX, Y)\n",
    "res = lm.predict(rbfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(penalty = \"l2\")\n",
    "lm.fit(rbfX, Y)\n",
    "res = lm.predict(rbfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        parameter     score\n",
      "5   [80, 2.0, 10]  0.821619\n",
      "2   [80, 1.0, 10]  0.809309\n",
      "1    [80, 1.0, 1]  0.802467\n",
      "4    [80, 2.0, 1]  0.800182\n",
      "8   [80, 4.0, 10]  0.797947\n",
      "7    [80, 4.0, 1]  0.791231\n",
      "3  [80, 2.0, 0.1]  0.786711\n",
      "0  [80, 1.0, 0.1]  0.786698\n",
      "6  [80, 4.0, 0.1]  0.658818\n"
     ]
    }
   ],
   "source": [
    "# cross validation on L1 regularized logistic regression\n",
    "from sklearn import cross_validation\n",
    "#alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "alphas = [0.1, 1, 10]\n",
    "#sigmas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "#sigmas = [0.1, 1.0, 10]\n",
    "sigmas = [1.0, 2.0, 4.0]\n",
    "#Ks = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 75, 80]\n",
    "#Ks = [5, 10, 20, 40, 80]\n",
    "Ks = [80]\n",
    "scores = []\n",
    "param = []\n",
    "for K in Ks:\n",
    "    centers = selectCenters(train_data.as_matrix(), K)\n",
    "    for sigma in sigmas:\n",
    "        rbfX = rbf(train_data.as_matrix(), centers, sigma)\n",
    "        for a in alphas:\n",
    "            lm = linear_model.LogisticRegression(penalty = \"l1\", C = a)\n",
    "            scores.append(cross_validation.cross_val_score(lm, rbfX, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "            param.append([K, sigma, a])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         parameter     score\n",
      "29   [80, 1.0, 10]  0.819372\n",
      "32   [80, 2.0, 10]  0.818186\n",
      "28    [80, 1.0, 1]  0.813741\n",
      "20   [40, 1.0, 10]  0.812642\n",
      "11   [20, 1.0, 10]  0.811544\n",
      "23   [40, 2.0, 10]  0.809209\n",
      "2    [10, 1.0, 10]  0.805838\n",
      "19    [40, 1.0, 1]  0.799096\n",
      "1     [10, 1.0, 1]  0.794589\n",
      "31    [80, 2.0, 1]  0.792367\n",
      "14   [20, 2.0, 10]  0.791243\n",
      "27  [80, 1.0, 0.1]  0.790107\n",
      "17   [20, 4.0, 10]  0.788983\n",
      "10    [20, 1.0, 1]  0.788971\n",
      "9   [20, 1.0, 0.1]  0.788958\n",
      "35   [80, 4.0, 10]  0.787897\n",
      "30  [80, 2.0, 0.1]  0.787834\n",
      "4     [10, 2.0, 1]  0.787822\n",
      "22    [40, 2.0, 1]  0.786748\n",
      "25    [40, 4.0, 1]  0.786711\n",
      "18  [40, 1.0, 0.1]  0.786711\n",
      "16    [20, 4.0, 1]  0.786711\n",
      "13    [20, 2.0, 1]  0.786711\n",
      "24  [40, 4.0, 0.1]  0.786698\n",
      "33  [80, 4.0, 0.1]  0.786698\n",
      "3   [10, 2.0, 0.1]  0.786698\n",
      "12  [20, 2.0, 0.1]  0.785587\n",
      "8    [10, 4.0, 10]  0.785587\n",
      "7     [10, 4.0, 1]  0.785575\n",
      "26   [40, 4.0, 10]  0.784526\n",
      "34    [80, 4.0, 1]  0.784488\n",
      "21  [40, 2.0, 0.1]  0.784463\n",
      "5    [10, 2.0, 10]  0.781181\n",
      "15  [20, 4.0, 0.1]  0.779969\n",
      "0   [10, 1.0, 0.1]  0.753228\n",
      "6   [10, 4.0, 0.1]  0.616170\n"
     ]
    }
   ],
   "source": [
    "# cross validation on L1 regularized logistic regression\n",
    "from sklearn import cross_validation\n",
    "#alphas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "alphas = [0.1, 1, 10]\n",
    "#sigmas = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1.0, 3.0, 10, 30, 100, 300, 1000, 3000]\n",
    "#sigmas = [0.1, 1.0, 10]\n",
    "sigmas = [1.0, 2.0, 4.0]\n",
    "#Ks = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 75, 80]\n",
    "#Ks = [5, 10, 20, 40, 80]\n",
    "Ks = [10, 20, 40, 80]\n",
    "scores = []\n",
    "param = []\n",
    "for K in Ks:\n",
    "    centers = selectCenters(train_data.as_matrix(), K)\n",
    "    for sigma in sigmas:\n",
    "        rbfX = rbf(train_data.as_matrix(), centers, sigma)\n",
    "        for a in alphas:\n",
    "            lm = linear_model.LogisticRegression(penalty = \"l2\", C = a)\n",
    "            scores.append(cross_validation.cross_val_score(lm, rbfX, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "            param.append([K, sigma, a])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = selectCenters(train_data.as_matrix(), 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 80\n"
     ]
    }
   ],
   "source": [
    "rbfX = rbf(train_data.as_matrix(), centers, 1.0)\n",
    "print(len(rbfX),len(centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.67328474, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.5       , 0.2963056 , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.49736115, 0.125     , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 0.72354863, 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.34005905, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [1.        , 0.24604172, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbfTest = rbf(test_data.as_matrix(), centers, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(penalty = \"l1\", C = 10)\n",
    "lm.fit(rbfX, Y)\n",
    "res = lm.predict(rbfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centers = selectCenters(train_data.as_matrix(), 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbfX = rbf(train_data.as_matrix(), centers, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rbfTest = rbf(test_data.as_matrix(), centers, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = linear_model.LogisticRegression(penalty = \"l2\", C = 10)\n",
    "lm.fit(rbfX, Y)\n",
    "res = lm.predict(rbfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "lm = linear_model.LogisticRegression(penalty = \"l1\", C = 3)\n",
    "lm.fit(train_data, Y)\n",
    "ada_lm = AdaBoostClassifier(lm)\n",
    "ada_lm.fit(train_data, Y)\n",
    "res = ada_lm.predict(test_data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.4 0.  0.  0.9 0.  1.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.\n",
      " 0.4 1.  0.  0.9 1.  0.2 1.  0.  1.  0.  0.  0.  0.  0.  0.7 0.8 0.4 0.\n",
      " 1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.9 0.  0.  1.  1.\n",
      " 0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  0.9 1.  1.  0.\n",
      " 0.8 0.2 1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  1.  1.\n",
      " 1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      " 0.  0.  0.  1.  1.  1.  1.  0.  0.  1.  0.7 1.  1.  0.  1.  0.  0.  1.\n",
      " 0.  0.4 0.  0.  0.  0.  0.5 0.  0.  0.  0.  0.  1.  0.  0.  1.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.8 0.  0.  1.  1.  0.  1.  1.  1.\n",
      " 1.  0.  0.  0.9 0.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.\n",
      " 0.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  0.6 0.  1.  0.  1.  1.\n",
      " 0.  1.  1.  0.9 0.  1.  0.  0.9 0.8 0.  1.  0.  0.  0.  0.  1.  0.  0.\n",
      " 1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.  1.  0.  0.\n",
      " 0.  0.  0.  0.  1.  1.  1.  1.  0.  0.  0.6 0.  1.  0.  1.  1.  1.  0.\n",
      " 0.7 0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.9 0.1 0.  0.  0.  1.  0.\n",
      " 0.4 0.  1.  1.  0.  1.  0.  0.  0.  0.  1.  0.9 1.  1.  0.9 0.  0.  0.\n",
      " 0.  0.  0.  1.  0.  1.  0.  0.  1.  0.  0.5 0.  0.  0.  0.  0.  1.  1.\n",
      " 0.  1.  0.  0.5 0.  0.  0.  0.8 1.  1.  0.  0.  0.  0.  0.  0.  0.  0.2\n",
      " 1.  0.  1.  0.  0.  0.  1.  0.1 0.  1.  0.  0.4 0.  0.  0.  1.  0.  0.\n",
      " 0.  1.  0.8 1.  0.  1.  0.  1.  1.  0.  0.  0.  0.9 0.  1.  0.  0.  1.\n",
      " 0.  1.  1.  0.  1.  0.1 0.  1.  1.  0.  0.  1.  0.  0.  1.  1.  0.  0.\n",
      " 0.  0.  0.  0.  1.  1.  0.  1.  0.  0.  0.  0.  0.9 1.  0.9 0.  0.  1.\n",
      " 0.  1.  0.  0.  1.  0.  1.  0.9 0.  0.1 0.  0.  1.  1.  1.  1.  0.9 0.\n",
      " 0.8 0.  0.  1. ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "lm = linear_model.LogisticRegression(penalty = \"l1\", C = 3)\n",
    "lm.fit(train_data, Y)\n",
    "ada_lm = BaggingRegressor(lm)\n",
    "ada_lm.fit(train_data, Y)\n",
    "res = ada_lm.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 1 0 0 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
      " 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "np.where(res>0.5, 1, 0)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 1 1 0 1 0 0 0 0 0 1 1 1 0 1\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "Vot_lm = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(train_data, Y)\n",
    "res = Vot_lm.predict(test_data)\n",
    "clf.score(X_test, y_test)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         parameter     score\n",
      "23  [3.0, l2, 160]  0.824928\n",
      "22   [3.0, l2, 80]  0.821557\n",
      "17  [1.0, l2, 160]  0.813679\n",
      "21   [3.0, l2, 40]  0.810308\n",
      "16   [1.0, l2, 80]  0.801319\n",
      "11  [0.3, l2, 160]  0.793478\n",
      "15   [1.0, l2, 40]  0.792367\n",
      "10   [0.3, l2, 80]  0.790094\n",
      "3    [0.1, l2, 40]  0.786698\n",
      "4    [0.1, l2, 80]  0.786698\n",
      "5   [0.1, l2, 160]  0.785587\n",
      "9    [0.3, l2, 40]  0.785587\n",
      "20  [3.0, l1, 160]  0.616170\n",
      "19   [3.0, l1, 80]  0.616170\n",
      "18   [3.0, l1, 40]  0.616170\n",
      "0    [0.1, l1, 40]  0.616170\n",
      "14  [1.0, l1, 160]  0.616170\n",
      "13   [1.0, l1, 80]  0.616170\n",
      "1    [0.1, l1, 80]  0.616170\n",
      "8   [0.3, l1, 160]  0.616170\n",
      "7    [0.3, l1, 80]  0.616170\n",
      "6    [0.3, l1, 40]  0.616170\n",
      "2   [0.1, l1, 160]  0.616170\n",
      "12   [1.0, l1, 40]  0.616170\n"
     ]
    }
   ],
   "source": [
    "numbers = [40, 80, 160]\n",
    "alphas = [0.1, 0.3, 1.0, 3.0]\n",
    "regs = [\"l1\", \"l2\"]\n",
    "scores = []\n",
    "param = []\n",
    "for alpha in alphas:\n",
    "    for reg in regs:\n",
    "        lm = linear_model.LogisticRegression(penalty = reg, C = alpha)\n",
    "        lm.fit(train_data, Y)\n",
    "        for number in numbers:\n",
    "            ada_lm = AdaBoostClassifier(lm, n_estimators = number)\n",
    "            scores.append(cross_validation.cross_val_score(ada_lm, train_data, Y, scoring=\"accuracy\", cv = 10).mean())\n",
    "            param.append([alpha, reg, number])\n",
    "scores = pd.DataFrame({'parameter': param, 'score': scores})\n",
    "print(scores.sort_values(by = 'score', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "lm = linear_model.LogisticRegression(penalty = \"l2\", C = 3.0)\n",
    "lm.fit(train_data, Y)\n",
    "ada_lm = AdaBoostClassifier(lm, n_estimators = 160)\n",
    "ada_lm.fit(train_data, Y)\n",
    "res = ada_lm.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save predictions\n",
    "sample_data = pd.read_csv(\"./data/gender_submission.csv\")\n",
    "sample_data['Survived'] = res\n",
    "sample_data.to_csv('./prediction.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
